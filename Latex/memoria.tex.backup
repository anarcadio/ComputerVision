\documentclass[a4paper,openright, 12pt]{book}
\usepackage[spanish]{babel} 
\usepackage[utf8]{inputenc} 
\usepackage{listings}
\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   
  basicstyle=\footnotesize,       
  breakatwhitespace=false,         
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Python,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=none,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                       % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}




\begin{document}

\begin{titlepage}
\begin{center}
\begin{Huge}
\textsc{Título}
\end{Huge}
\end{center}
\end{titlepage}

\newpage
\mbox{}
\thispagestyle{empty} 


\tableofcontents % indice de contenidos
\thispagestyle{empty}


\chapter{Introducción}\label{cap.introduccion}
\pagenumbering{arabic} % para empezar la numeración con números

\section{Motivación}


\chapter{OpenCV}

\section{Introducción}
OpenCV es una librería de código abierto escrita en C y C++ destinada a la visión artificial y al tratamiento de imágenes. Se trata de una librería multiplataforma con versiones para GNU/Linux, Windows, Mac OS y Android y actualmente cuenta con interfaces para Python, Java y MATLAB/OCTAVE. Las últimas versiones incluyen soporte para GPU usando CUDA.
Desarrollada originalmente por Intel, su primera versión alfa se publicó en el año 2000 en el \textit{IEEE Conference on Computer Vision and Pattern Recognition}. OpenCV nació inicialmente como un proyecto para avanzar en las aplicaciones de uso intenso de la CPU y dando gran importancia a las aplicaciones en tiempo real. Hoy en día cuenta con más 2500 algoritmos optimizados que abarcan todo tipo de campos relacionados con la visión artificial.
Estos algortimos pueden ser usados para tareas como: detectar y reconocer caras y gestos, identificar objetos, detección de características 2D y 3D, estimación de movimiento, seguimiento del movimiento, visión estéro y calibración de la cámara, eliminar los ojos rojos de las fotografías realizadas con flash...
\newline
OpenCV es ampliamente utilizada por todo tipo de empresas (desde grandes empresas como Google, Yahoo, Microsoft, Intel, IBM, Sony, Honda, Toyota a pequeñas empresas), grupos de investigación y organismos gubernamentales y en sectores de todo tipo como: inspección de los productos en las fábricas, seguridad, usos médicos, robótica...
\newline
\section{Ejemplos}
A continuación veremos una serie de ejemplos sencillos de uso de openCV con python, similares a los propuestos en el capítulo 2 de "Learning OpenCV" \cite{oreilly}
\subsection*{Ejemplo 1}
En primer lugar veamos como mostrar una imagen en una ventana
\lstinputlisting[language=Python, frame= single]{ejemplos/ejemplo1.py}
Como vemos se trata de un código muy sencillo. Al ser ejecutado con un argumento, carga una imagen y la muestra en una ventana; luego espera hasta que el usuario pulse una tecla.

La función \lstinline|cv2.imread()| es la que se encarga de cargar la imagen desde un archivo. 

Según la documentación de openCV, la función 
\lstinline|cv2.imread(filename[, flags])|
toma como parámetros:
\begin{itemize}

\item filename: Es el nombre del archivo que se quiere abrir.
\item flags:
Especifican el modo de color en que se carga la imagen:
\begin{itemize}
\item \lstinline|CV_LOAD_IMAGE_ANYDEPTH|: Devuelve una imagen de 16-bit/32-bit cuando la entrada tiene la correspondiente profundidad, en otro caso la convierte a 8-bit.
\item \lstinline|CV_LOAD_IMAGE_COLOR|: Convierte la imagen a color
\item \lstinline|CV_LOAD_IMAGE_GRAYSCALE|: Convierte la imagen a escala de grises
\item $>0$ Devuelve una imagen de 3 canales de color.

\item $=0$ Devuelve una imagen en escala de grises.
\item $<0$ Return the loaded image as is (with alpha channel).
\end{itemize}
\end{itemize}
La función devuelve la imagen (en forma de array de numpy).
\newline
Una vez hemos cargado la imagen, la mostramos en una ventana usando \lstinline|cv2.imshow(winname, image)|, donde \lstinline|winname| es el nombre de la ventana e \lstinline|image| es la imagen que queremos mostrar.
Por último, utilizamos \lstinline|cv2.waitKey(0)| para esperar a que el usuario pulse una tecla. Esta función recibe un único parámetro que indica el tiempo, en milisegundos, a esperar para la pulsación de una tecla. Si este parámetro es menor o igual que cero, esperará indefinidamente.

\newpage

\subsection*{Ejemplo 2}
En el siguiente ejemplo vemos como cargar un archivo de video y mostrarlo en una ventana. El programa termina cuando el video se acaba o cuando el usuario pulsa la tecla Esc
\lstinputlisting[language=Python, frame= single]{ejemplos/ejemplo2.py}
En este ejemplo hemos hecho uso de la clase VideoCapture.
La función \lstinline|cv2.VideoCapture(filename)| recibe como argumento el nombre de un archivo de vídeo o la ID de un dispositivo de video (en este caso un nombre de archivo) y devuelve un objeto de la clase VideoCapture.
De esta clase tan solo usamos ahora la función \lstinline|cv2.VideoCapture.read()| que toma el siguiente fotograma, lo decodifica y lo devuelve. Además de la imagen, devuelve un booleano, que en el código hemos llamado ret, que es False si ningún fotograma ha sido tomado y True en otro caso.
Como ahora ya tenemos una imagen, para mostrarla por pantalla usamos la misma función que en el ejemplo 1.
Por último esta vez usamos la función \lstinline|cv2.waitKey| de manera un poco distinta al anterior ejemplo. Como ahora estamos en un bucle, esperamos a la pulsación 33 milisegundos. Si alguna tecla es pulsada, su valor ASCII se almacena y lo comparamos con 27 que es el correspondiente a la tecla Esc.

\newpage
\subsection*{Ejemplo 3}
En este ejemplo mejoraremos un poco el reproductor de video que hemos programado en el ejemplo anterior. Se ha añadido un slider con el instante del video en que nos encontramos, el cual se puede utilizar para avanzar y retroceder hasta donde deseemos.
\lstinputlisting[language=Python, frame= single]{ejemplos/ejemplo3.py}
Como vemos, en este código hemos introducido unas cuantas funciones nuevas.
En primer lugar, hemos usado varias veces la función \lstinline|cv2.VideoCapture.get(propId)| con distintos argumentos.
Esta función devuelve el valor de distintas propiedades del video con el que estamos trabajando. El argumento es el identificador de la propiedad y puede ser uno de los siguientes según la documentación:
\begin{itemize}

    \item \lstinline|CV_CAP_PROP_POS_MSEC| Posición actual en el video en milisegundos o el "timestamp" del capturador de video.
    \item \lstinline|CV_CAP_PROP_POS_FRAMES| Posición del próximo fotograma que va a ser decodificado/capturado.
    \item \lstinline|CV_CAP_PROP_POS_AVI_RATIO| Posición relativa del video, siendo 0 el inicio del video y 1 el final.
  
    \item \lstinline|CV_CAP_PROP_FRAME_WIDTH| Anchura de los fotogramas del video.
    \item \lstinline|CV_CAP_PROP_FRAME_HEIGHT| Altura de los fotogramas del video.
    \item \lstinline|CV_CAP_PROP_FPS| Fotogramas por segundo.
    \item \lstinline|CV_CAP_PROP_FOURCC| Código de 4 caracteres del codec usado.
    \item \lstinline|CV_CAP_PROP_FRAME_COUNT| Número de fotogramas en el archivo de video.
    \item \lstinline|CV_CAP_PROP_FORMAT| Format of the Mat objects returned by retrieve() .
    \item \lstinline|CV_CAP_PROP_MODE| Backend-specific value indicating the current capture mode.
    \item \lstinline|CV_CAP_PROP_BRIGHTNESS| Brillo de la imagen (solo para cámaras).
    \item \lstinline|CV_CAP_PROP_CONTRAST| Contraste de la imagen (solo para cámaras).
    \item \lstinline|CV_CAP_PROP_SATURATION| Saturación de la imagen (solo para cámaras).
    \item \lstinline|CV_CAP_PROP_HUE| Tono de la imagen (solo para cámaras).
    \item \lstinline|CV_CAP_PROP_GAIN| Ganancia de la imagen (solo para cámaras)..
    \item \lstinline|CV_CAP_PROP_EXPOSURE| Exposición (solo para cámaras).
    \item \lstinline|CV_CAP_PROP_CONVERT_RGB| Boolean flags indicating whether images should be converted to RGB.
\end{itemize}
También usamos la función \lstinline|cv2.VideoCapture.set(propId, value)|, usada para fijar el valor de alguna de las propiedades del vídeo. Por tanto los valores que puede tomar \lstinline|propId| son los mismos que para la función \lstinline|cv2.VideoCapture.get()| y el argumento \lstinline|value| indica el nuevo valor que tomará la propiedad indicada.

Una vez cargamos el video como ya sabemos y obtenemos el número total de frames con la función \lstinline|get| como acabamos de ver, procedemos a crear una ventana con la función \lstinline|cv2.namedWindow(winname[, flags]).
Hasta ahora no había hecho falta ya que \lstinline|cv2.imshow| creaba una nueva ventana si no existía una con ese nombre.
Ahora le vamos a añadir algo (una trackbar) a nuestra ventana, por lo que necesitamos que ya esté creada.
Para esto usamos \lstinline|cv2.createTrackbar(trackbarName, windowName, value, count, onChange)|, siendo estos parámetros:
\begin{itemize}
 \item trackbarname – Name of the created trackbar.
 \item winname – Name of the window that will be used as a parent of the created trackbar.
 \item value – Optional pointer to an integer variable whose value reflects the position of the slider. Upon creation, the slider position is defined by this variable.
 \item count – Maximal position of the slider. The minimal position is always 0.
onChange – Pointer to the function to be called every time the slider changes position. This function should be prototyped as void Foo(int,void*); , where the first parameter is the trackbar position and the second parameter is the user data (see the next parameter). If the callback is the NULL pointer, no callbacks are called, but only value is updated.
\end{itemize}

\newpage

\subsection*{Ejemplo 4}
\lstinputlisting[language=Python, frame= single]{ejemplos/ejemplo4.py}
\newpage

\subsection*{Ejemplo 5}
\lstinputlisting[language=Python, frame= single]{ejemplos/ejemplo5.py}
\lstinputlisting[language=Python, frame= single]{ejemplos/ejemplo7.py}
\lstinputlisting[language=Python, frame= single]{ejemplos/ejemplo9.py}
\lstinputlisting[language=Python, frame= single]{ejemplos/BlurCam.py}

\newpage
\chapter{Otras librerías usadas}
\section{Android}

Android es un sistema operativo desarrollado por Google y orientado a móviles y tablets. Está basado en linux y es de código abierto. Actualmente se estima que en torno un 80\% de los dispositívos móviles usan el sistema operativo Android.
Su núcleo está programado en C, pero la aplicaciones y toda la interfaz de usuario se programan en Java.
Este sistema operativo está estructurado en 4 capas:
\begin{description}
  \item[Núcleo linux] \hfill \\
  Se encarga de las funcionalidades básicas del sistema, como manejo de procesos, de la memoria y de los dispositivos como la cámara, la pantalla, etc.
   Asimismo funciona como una capa de abstracción entre el hardware y el resto del software.
   
  \item[Librerías y Runtime de Android] \hfill \\
  Por encima del núcleo, hay una serie de librerías usadas por componentes del sistema, entre ellas destacan Surface Manager, Media Framework, SQLite, WebKit, SGL y Open GL
  \newline
  El runtime de Android proporciona un componente clave,la máquina virtual Dalvik. Cada aplicación Android corre su propio proceso, con su propia instancia de esta máquina virtual.
  Además, el runtime de android proporciona librerías básicas que proporcionan la mayor parte de las funciones del lenguaje de programación Java.
  
  \item[Framework de aplicaciones] \hfill \\
  Esta capa proporciona a las aplicaciones muchos servicios en forma de clases de Java 
  
   \item[Aplicaciones] \hfill \\
  En esta capa se encuentran tanto las aplicaciones base como las que instalemos y desarrollemos   \ldots
\end{description}

\subsection*{Estructura de una aplicación Android}
Las aplicaciones android están por los llamados componentes de aplicación. Hay cuatro tipo de componentes:
\begin{description}
  \item[Activities] \hfill \\
  Representa una única pantalla de la aplicación con su interfaz de usuario.
  \item[Services] \hfill \\
  Son componentes que se ejecutan en segundo plano y que no constan de interfaz gráfica.
  \item[Content providers] \hfill \\
  \item[Broadcast receivers] \hfill \\
\end{description}

\chapter{Estabilización de imagen}\label{cap.}

\section{Algoritmo}
Se trata de un algoritmo básico de estabilización de imagen que se basa en la suposición de que el único movimiento de la cámara es el que queremos eliminar; es decir, excepto por ligeros movimientos no deseados, la cámara está estática.
La idea del algoritmo es muy sencilla: 
Tomamos dos frames consecutivos y buscamos una serie de puntos característicos mediante el algoritmo propuesto por Shi y Tomashi \cite{shiandtomasi}, usando la función: \lstinline{goodFeaturesToTrack}; después vemos a donde se han movido esos puntos en el siguiente frame mediante el algoritmo de flujo óptico de Lucas-Kanade.
Finalmente calculamos la homografía que lleva los puntos originales a donde hemos calculado que se han movido y le aplicamos la inversa de esa transformación al segundo frame para colocarlo donde debería estar.
\subsection{Encontrar puntos característicos}

EXPLICACIÓN
\subsection{Algoritmo de Lucas-Kanade}
EXPLICACIÓN

\subsection{Codigo}
\lstinputlisting[language=Python, frame= single]{estabilizacion.py}

\section{Uso del acelerometro para estabilizar}
Se trata de intentar utilizar los datos extra de los que disponemos, es decir, los que nos proporciona el acelerómetro del móvil para intentar estabilizar la imagen utilizando estos datos.
Para ello en primer lugar hacemos un programa para android que se encarga de recoger estos datos, grabando el vídeo a la vez que registra los datos del acelerómetro y los guarda en un archivo junto con el momento exacto en el que se han registrado los datos.
Luego, un segundo programa en el ordenador procesa los archivos para intentar estabilizar la imagen: recoge los datos de aceleración en cada instante de media y aproxima el movimiento en dichos instantes. Luego calcula mediante interpolación cuanto se ha movido la cámara en el instante del fotograma y recoloca el fotograma de acuerdo con lo obtenido.

\subsection{Programa para Android}


\subsection{Programa de procesado de los datos}
\lstinputlisting[language=Python, frame= single]{estabilizacion_acelerometro.py}

\subsection{Resultados}

\cleardoublepage
\addcontentsline{toc}{chapter}{Bibliografía}
\bibliographystyle{plain} % estilo de la bibliografía.
\bibliography{texto} % texto.bib es el fichero donde está salvada la bibliografía.


\end{document}
